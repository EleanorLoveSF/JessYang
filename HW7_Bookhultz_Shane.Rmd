---
title: "HW7 Shane Bookhultz"
output: html_notebook
---

## Libraries used

```{r echo = F, warning=FALSE}
suppressWarnings(library(foreach, warning(F)))
suppressWarnings(library(doParallel, warning(F)))
suppressWarnings(library(knitr, warning(F)))
suppressWarnings(library(doRNG, warning(F)))
```



## Problem 2

-Calculate sums of squares using...

```{r echo = F}

# Generating the data for problem 2

set.seed(12345)
y <- rnorm(n = 10000, mean = 1, sd = 1)

```

a. For loop

```{r echo = F}
#2a calculating sums of squares using a for loop, calculating the summed squared difference between data points and the mean of the data

SSval <- 0

t1 <- system.time({
  meany <- mean(y)
  for(i in 1:length(y)){
    SSval <- SSval + (y[i] - meany)^2
  }
})

# time for user is 3.66, system is 0.52, and elapsed is 4.32

```

b. Vector operations

```{r echo = F}
#2b Using vector operations to do the same computation

SSval2 <- 0

t2 <- system.time({
  meany <- mean(y)
  SSval2 <- t(y-meany) %*% (y-meany)
})

# User is 0.05, system is 0.00, elapsed is 0.05

```

c. dopar

```{r echo = F}
#2c Use dopar to calculate sums of squares

#detectCores()
# I have 4 cores

cl <- makeCluster(3)
registerDoParallel(cl)

t3 <- system.time({
  ParSum <- foreach(j = 1:length(y), .combine ="+") %dopar% {
    sum((y[j]-meany)^2)
  }
})

stopCluster(cl)

# Stopped at 6606 324.8 7505 with y = 1e+07

```

d. parSapply

```{r echo = F}
#2d 

registerDoParallel(cl)
cl <- makeCluster(3)

sumsvec <- vector()

SUM <- function (m) {
  sums <- (m-mean(m))^2
  return (sums)
} 

clusterExport(cl, "SUM")

t4 <- system.time({
  SapSum <- parSapply(cl, 1:length(y), function(y) SUM)
})

stopCluster(cl)

t1 <- t1[1:3]
t2 <- t2[1:3]
t3 <- t3[1:3]
t4 <- t4[1:3]

timedf <- data.frame(rbind(t1,t2,t3,t4))
colnames(timedf) <- c("User", "System", "Elapsed")
rownames(timedf) <- c("For", "Vector ops", "Dopar", "parSapply" )

kable(timedf)


```

I see that overall, the For, vector operations and parSapply take the least amount of time, where Dopar take an unusual amount of time to run. 

My final sums of squares is 9996. With n = 10000. 

## 3. Gradient Descent

```{r echo = F}

#3 Gradient Descent

# what to parallelize here? What parameters do you NEED to specify

# compare to lm(h~0+x)

# Original results

set.seed(1256)
theta <- as.matrix(c(1,2), nrow = 2)
x <- cbind(1, rep(1:10, 10))

alpha <- 0.0001
tolerance <- 0.000001

# Theta new is theta i 
# Theta current is theta i - 1
# Alpha doesnt change, and tolerance are set
# h is devised from x and theta, m comes from h
# Theta current and theta

getGradient <- function(xvec, thetamat) {
  # This function takes in an xvec and theta matrix
  # It calculates the coefficients in a regression model
  
  set.seed(1256)
  
  thetacurrent <- as.matrix(c(0,0), nrow = 2)
  thetanew <- as.matrix(c(1,1), nrow = 2)
  h <- xvec %*% thetamat + rnorm(100, 0, 0.2)
  m <- length(h)
  tx <- t(xvec)
  
  
  t5 <- system.time({
    while(sum(abs(thetanew - thetacurrent) > tolerance)) {
      thetacurrent <- thetanew
      thetagrad <- tx %*% ((x %*% thetacurrent) - h)
      thetanew <- thetacurrent - alpha/m * thetagrad
    }
  })
  
  mydf <- data.frame(thetacurrent, thetanew)
  rownames(mydf) <- c("Theta0", "Theta1")
  colnames(mydf) <- c("Thetacurrent", "Thetanew")
  
  return (mydf)
}

grad <- getGradient(x, theta)

# now to parallelize this function


registerDoParallel(3)
cl <- makeCluster(3)

clusterExport(cl, "getGradient")

parattempt <- parSapply(cl, function(x, theta) getGradient, getGradient)

stopCluster(cl)

lmfit <- lm(h~0+x)


```

So I wasn't able to get the parSapply or parLapply to work with a function. However, I was able to make a getGradient function that only needs an x matrix and theta matrix to calculate the gradient (coefficients) for the linear model. I wanted to parallelize this by creating the function and by using the parallel function parSapply to parallelize the function and make it faster.

## 4. Bootstrapped regression 

```{r echo = F}
#4a. Bootstrapped regression

B = 10000

bootbeta <- matrix(NA, ncol = 5, nrow = 10000)

Boottime <- list()

set.seed(1267)
n <- 200
X <- 1/cbind(1, rt(n, df = 1), rt(n, df = 1), rt(n, df = 1))
beta <- c(1,2,3,0)
Y <- X %*% beta + rnorm(100, sd = 3)

cl <- makeCluster(3)
registerDoParallel(cl)
registerDoRNG()
set.seed(1267)

t6 <- system.time({Boottime <- foreach(b = 1:B, .combine = "rbind") %dorng% {
  bootid <- sample(1:length(Y), length(Y), replace = TRUE)
  bootx <- X[bootid, ]
  booty <- Y[bootid, ]
  return (bootbeta <- coef(lm(booty~bootx)))
}
})
 
stopCluster(cl)

# since considering beta1, use index 2

# This above function works now but only because I didn't have extra parentheses

# I did Booty ~ 0 + bootX in order to remove the list of 1's


```

a. I used the base package of R to generate my random data. I used the parallelization method of DoRNG. This is needed because each time the for loop is ran, a different sample is run, and normal seeds do not work with parallel loops, so the dorng statement must be used for reproducibility. I encounter a full 2 hour straight impediment of having an extra parentheses around the iteration step in the foreach loop, which I later deleted. This one reduction in parentheses allowed me to fully run the foreach loop. This process took me 9.27 seconds overall. 

b. 

```{r echo = F}

#4b creating a summary table of the betas

# I will get the mean of the beta's, the variance in the betas and the min and max

meanbetas <- apply(Boottime, 2, mean)
minbetas <- apply(Boottime, 2, min)
maxbetas <- apply(Boottime, 2, max)
varbetas <- apply(Boottime, 2, var)

sumtable <- cbind(minbetas, maxbetas, meanbetas, varbetas)

kable(sumtable)
```

c. Create histograms of the Betas (Will only use the intercept and bootx2-4, since bootx1 is just all NA's.)

```{r echo = F}

#4c creating histograms of the betas

#par(mfrow = c(2,2))
hist(Boottime[,1], main = "Intercept Beta", xlab = "Intercept")
hist(Boottime[,3], main = "Beta2", xlab = "Beta2")
hist(Boottime[,4], main = "Beta3", xlab = "Beta3")
hist(Boottime[,5], main = "Beta4", xlab = "Beta4")

```

## Appendix

```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=60), }

```